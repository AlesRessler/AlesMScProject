{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ee973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "from models.neuralnetwork.fully_connected import FullyConnected4Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5075c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWDataset(Dataset):\n",
    "    def __init__(self, spherical_harmonics_coefficients, measurements):\n",
    "        self.X = measurements\n",
    "        self.y = spherical_harmonics_coefficients\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return [self.X[index], self.y[index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39c7a2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d6d82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DWDataset.__init__() missing 1 required positional argument: 'measurements'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDWDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m train, validation, test \u001b[38;5;241m=\u001b[39m random_split(dataset, [\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.2\u001b[39m], generator\u001b[38;5;241m=\u001b[39mgenerator)\n",
      "\u001b[0;31mTypeError\u001b[0m: DWDataset.__init__() missing 1 required positional argument: 'measurements'"
     ]
    }
   ],
   "source": [
    "dataset = DWDataset(...)\n",
    "\n",
    "generator = torch.Generator().manual_seed(1)\n",
    "\n",
    "train, validation, test = random_split(dataset, [0.6,0.2,0.2], generator=generator)\n",
    "\n",
    "train_data_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "validation_data_loader = DataLoader(validation, batch_size=32, shuffle=True)\n",
    "test_data_loader = DataLoader(test, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6694d25",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82019e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "model = FullyConnected4Layers(number_of_inputs=..., number_of_outputs=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    # Mini batches\n",
    "    for i, (inputs, targets) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yhat = model(inputs)\n",
    "        \n",
    "        loss_evaluation = loss(yhat, targets)\n",
    "        \n",
    "        loss_evaluation.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f5488",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, actuals = list(), list()\n",
    "\n",
    "for i, (inputs, targets) in enumerate(test_data_loader):\n",
    "    yhat = model(inputs)\n",
    "    \n",
    "    yhat = yhat.detach().numpy()\n",
    "    \n",
    "    actual = targets.numpy()\n",
    "    actual = actual.reshape((len(actual), 1))\n",
    "    \n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    actuals.append(actual)\n",
    "\n",
    "predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "\n",
    "mse_final_loss = loss(predictions, actuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
